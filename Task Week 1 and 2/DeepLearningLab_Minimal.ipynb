{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Deep Learning Fundamentals \u2014 Minimal Notebook\n", "Minimal lab version. Tasks: tensors, FFNN, gradient check, CNN, LR sweep, conv arithmetic.\n", "Author: student\n"]}, {"cell_type": "code", "metadata": {}, "source": ["import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torchvision\n", "import torchvision.transforms as T\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "\n", "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n", "torch.manual_seed(1337)\n", "print('Device:', device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load dataset (MNIST)"]}, {"cell_type": "code", "metadata": {}, "source": ["transform = T.Compose([T.ToTensor()])\n", "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n", "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n", "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n", "test_loader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\n", "imgs, labels = next(iter(train_loader))\n", "plt.imshow(imgs[0][0], cmap='gray')\n", "plt.title(f'label: {labels[0].item()}')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## FFNN model + training"]}, {"cell_type": "code", "metadata": {}, "source": ["class FFNN(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.fc1 = nn.Linear(28*28, 128)\n", "        self.fc2 = nn.Linear(128, 10)\n", "    def forward(self, x):\n", "        x = x.view(x.size(0), -1)\n", "        x = F.relu(self.fc1(x))\n", "        x = self.fc2(x)\n", "        return x\n", "\n", "model = FFNN().to(device)\n", "opt = torch.optim.SGD(model.parameters(), lr=0.05)\n", "criterion = nn.CrossEntropyLoss()\n", "for epoch in range(3):\n", "    model.train()\n", "    total_loss = 0\n", "    for x, y in train_loader:\n", "        x, y = x.to(device), y.to(device)\n", "        opt.zero_grad()\n", "        out = model(x)\n", "        loss = criterion(out, y)\n", "        loss.backward()\n", "        opt.step()\n", "        total_loss += loss.item()\n", "    print(f'Epoch {epoch+1}, loss={total_loss/len(train_loader):.4f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Gradient check (tiny network example)"]}, {"cell_type": "code", "metadata": {}, "source": ["eps = 1e-4\n", "x = torch.randn(5, 3, device=device)\n", "W = nn.Parameter(torch.randn(2, 3, device=device)*0.1)\n", "b = nn.Parameter(torch.zeros(2, device=device))\n", "y = torch.randint(0, 2, (5,), device=device)\n", "\n", "def forward_fc(x):\n", "    return x @ W.T + b\n", "\n", "out = forward_fc(x)\n", "loss = F.cross_entropy(out, y)\n", "loss.backward()\n", "grad_W = W.grad.clone().flatten()\n", "\n", "num_grad = []\n", "for i in range(W.numel()):\n", "    old = W.data.flatten()[i].item()\n", "    W.data.flatten()[i] = old + eps\n", "    l1 = F.cross_entropy(forward_fc(x), y).item()\n", "    W.data.flatten()[i] = old - eps\n", "    l2 = F.cross_entropy(forward_fc(x), y).item()\n", "    W.data.flatten()[i] = old\n", "    num_grad.append((l1 - l2)/(2*eps))\n", "\n", "rel_err = torch.norm(grad_W - torch.tensor(num_grad, device=device)) / torch.norm(grad_W + torch.tensor(num_grad, device=device))\n", "print('Relative error:', rel_err.item())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## CNN model + quick training"]}, {"cell_type": "code", "metadata": {}, "source": ["class SimpleCNN(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.conv1 = nn.Conv2d(1, 8, 5, padding=2)\n", "        self.pool = nn.MaxPool2d(2)\n", "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n", "        self.fc1 = nn.Linear(16*14*14, 64)\n", "        self.fc2 = nn.Linear(64, 10)\n", "    def forward(self, x):\n", "        x = self.pool(F.relu(self.conv1(x)))\n", "        x = F.relu(self.conv2(x))\n", "        x = x.view(x.size(0), -1)\n", "        x = F.relu(self.fc1(x))\n", "        x = self.fc2(x)\n", "        return x\n", "\n", "cnn = SimpleCNN().to(device)\n", "opt = torch.optim.SGD(cnn.parameters(), lr=0.01)\n", "crit = nn.CrossEntropyLoss()\n", "for epoch in range(3):\n", "    cnn.train()\n", "    total_loss = 0\n", "    for x, y in train_loader:\n", "        x, y = x.to(device), y.to(device)\n", "        opt.zero_grad()\n", "        out = cnn(x)\n", "        loss = crit(out, y)\n", "        loss.backward()\n", "        opt.step()\n", "        total_loss += loss.item()\n", "    print(f'[CNN] Epoch {epoch+1}, loss={total_loss/len(train_loader):.4f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## LR sweep"]}, {"cell_type": "code", "metadata": {}, "source": ["lrs = [0.005, 0.05, 0.5]\n", "results = {}\n", "for lr in lrs:\n", "    model = FFNN().to(device)\n", "    opt = torch.optim.SGD(model.parameters(), lr=lr)\n", "    crit = nn.CrossEntropyLoss()\n", "    for epoch in range(3):\n", "        model.train()\n", "        for x, y in train_loader:\n", "            x, y = x.to(device), y.to(device)\n", "            opt.zero_grad()\n", "            out = model(x)\n", "            loss = crit(out, y)\n", "            loss.backward()\n", "            opt.step()\n", "    model.eval()\n", "    correct, total = 0, 0\n", "    with torch.no_grad():\n", "        for x, y in test_loader:\n", "            x, y = x.to(device), y.to(device)\n", "            preds = model(x).argmax(1)\n", "            correct += (preds==y).sum().item()\n", "            total += y.size(0)\n", "    results[lr] = correct/total\n", "print('LR sweep results:', results)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conv arithmetic check"]}, {"cell_type": "code", "metadata": {}, "source": ["def conv_out(h, k, s, p, d):\n", "    return int((h + 2*p - d*(k-1) - 1)/s + 1)\n", "\n", "for (h, k, s, p, d) in [(28,5,1,2,1),(28,3,2,1,1),(32,3,1,0,1),(64,7,2,3,1),(64,3,1,1,2)]:\n", "    x = torch.zeros(1,1,h,h)\n", "    conv = nn.Conv2d(1,1,k,s,p,d)\n", "    y = conv(x)\n", "    print((h,k,s,p,d), 'formula:', conv_out(h,k,s,p,d), 'torch:', y.shape[-1])"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cec318",
   "metadata": {},
   "source": [
    "# Deep Learning Lab â€” Mustafa\n",
    "Minimal notebook with FFNN, CNN, LR sweep and convolution arithmetic checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86075f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_seed(seed: int = 1337):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    return seed\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def save_plot(fig, outpath: str, title: str = \"\"):\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outpath, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "outputs_dir = \"./outputs\"\n",
    "ensure_dir(outputs_dir)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d363d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1   = nn.Linear(16*14*14, 64)\n",
    "        self.fc2   = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e844933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_loaders(batch_size=64):\n",
    "    tfm = transforms.Compose([transforms.ToTensor()])\n",
    "    train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "    test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=tfm)\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
    "        DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "    )\n",
    "\n",
    "train_loader, test_loader = get_mnist_loaders(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a4b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct=0; total=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred==y).sum().item()\n",
    "            total += y.numel()\n",
    "    return correct/total\n",
    "\n",
    "def train_model(model, train_loader, test_loader, lr=0.01, epochs=3, prefix=\"model\"):\n",
    "    model.to(device)\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    losses, accs = [], []\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss=0; steps=0\n",
    "        for x,y in train_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out,y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss+=loss.item(); steps+=1\n",
    "        loss_avg = total_loss/max(1,steps)\n",
    "        acc = evaluate(model,test_loader)\n",
    "        losses.append(loss_avg); accs.append(acc)\n",
    "        print(f\"[{prefix}] epoch={ep} loss={loss_avg:.4f} acc={acc:.4f}\")\n",
    "    # Plots\n",
    "    fig1 = plt.figure()\n",
    "    plt.plot(range(1,epochs+1), losses, marker='o')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'{prefix} loss')\n",
    "    save_plot(fig1, os.path.join(outputs_dir, f\"{prefix}_loss.png\"))\n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    plt.plot(range(1,epochs+1), accs, marker='o')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title(f'{prefix} accuracy')\n",
    "    save_plot(fig2, os.path.join(outputs_dir, f\"{prefix}_acc.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05fa754",
   "metadata": {},
   "source": [
    "## FFNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = FFNN()\n",
    "train_model(ffnn, train_loader, test_loader, lr=0.05, epochs=3, prefix=\"ffnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c28f5",
   "metadata": {},
   "source": [
    "## CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = SimpleCNN()\n",
    "train_model(cnn, train_loader, test_loader, lr=0.01, epochs=3, prefix=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86526cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = cnn.conv1.weight.cpu()\n",
    "    fmin = w.min(dim=-1, keepdim=True)[0].min(dim=-2, keepdim=True)[0]\n",
    "    fmax = w.max(dim=-1, keepdim=True)[0].max(dim=-2, keepdim=True)[0]\n",
    "    w_norm = (w - fmin) / (fmax - fmin + 1e-8)\n",
    "\n",
    "    cols = w_norm.shape[0]\n",
    "    fig, axes = plt.subplots(1, cols, figsize=(2*cols, 2))\n",
    "    if cols == 1: axes = [axes]\n",
    "    for i in range(cols):\n",
    "        axes[i].imshow(w_norm[i,0].numpy(), cmap=\"gray\")\n",
    "        axes[i].set_title(f\"F{i}\")\n",
    "        axes[i].axis(\"off\")\n",
    "    save_plot(fig, os.path.join(outputs_dir, \"cnn_filters_conv1.png\"), title=\"First-layer conv filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826e62b4",
   "metadata": {},
   "source": [
    "## Learning Rate Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea3b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.005, 0.05, 0.5]\n",
    "logs = {}\n",
    "for lr in lrs:\n",
    "    model = FFNN()\n",
    "    logs[lr] = train_model(model, train_loader, test_loader, lr=lr, epochs=3, prefix=f\"sweep_lr_{str(lr).replace('.','_')}\")\n",
    "\n",
    "fig = plt.figure()\n",
    "for lr in lrs:\n",
    "    plt.plot(range(1,4), logs[lr], label=f\"lr={lr}\")\n",
    "plt.legend(); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Learning rate sweep')\n",
    "save_plot(fig, os.path.join(outputs_dir, \"sweep_loss_compare.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a6824",
   "metadata": {},
   "source": [
    "## Convolution Arithmetic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_out_size(H, W, k, s, p, d=1):\n",
    "    def one_dim(n):\n",
    "        return math.floor((n + 2*p - d*(k-1) - 1)/s + 1)\n",
    "    return one_dim(H), one_dim(W)\n",
    "\n",
    "cases = [(28,28,5,1,2,1),\n",
    "         (28,28,3,2,1,1),\n",
    "         (32,32,3,1,0,1),\n",
    "         (64,64,7,2,3,1),\n",
    "         (64,64,3,1,1,2)]\n",
    "rows = []\n",
    "for (H,W,k,s,p,d) in cases:\n",
    "    h_out, w_out = conv_out_size(H,W,k,s,p,d)\n",
    "    x = torch.randn(1,1,H,W)\n",
    "    conv = nn.Conv2d(1,1,k,s,p,d)\n",
    "    with torch.no_grad():\n",
    "        y = conv(x)\n",
    "    rows.append((H,W,k,s,p,d,h_out,w_out,y.shape[-2],y.shape[-1]))\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.axis(\"off\")\n",
    "text = \"H  W | k s p d | formula(H,W) | torch(H,W)\\n\" + \"-\"*48 + \"\\n\"\n",
    "for r in rows:\n",
    "    text += f\"{r[0]:>2} {r[1]:>2} | {r[2]} {r[3]} {r[4]} {r[5]} | ({r[6]:>2},{r[7]:>2}) | ({r[8]:>2},{r[9]:>2})\\n\"\n",
    "plt.text(0.02,0.98,text,va=\"top\",family=\"monospace\")\n",
    "save_plot(fig, os.path.join(outputs_dir, \"conv_arith_checks.png\"))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
